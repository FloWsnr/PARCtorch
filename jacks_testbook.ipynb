{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8046f209-59a4-473d-8cf2-8bcd66777cec",
   "metadata": {},
   "source": [
    "# Testing UNET Functionality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bb2e013-dc74-4f39-9d07-66fe30b86a65",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Input Shape: torch.Size([1, 5, 144, 240])\n",
      "After Initial DoubleConv: torch.Size([1, 5, 144, 240])\n",
      "DownBlock Input Shape: torch.Size([1, 5, 144, 240])\n",
      "After DoubleConv DownBlock: torch.Size([1, 128, 144, 240])\n",
      "After Pooling DownBlock: torch.Size([1, 128, 72, 120])\n",
      "DownBlock Input Shape: torch.Size([1, 128, 72, 120])\n",
      "After DoubleConv DownBlock: torch.Size([1, 256, 72, 120])\n",
      "After Pooling DownBlock: torch.Size([1, 256, 36, 60])\n",
      "DownBlock Input Shape: torch.Size([1, 256, 36, 60])\n",
      "After DoubleConv DownBlock: torch.Size([1, 512, 36, 60])\n",
      "After Pooling DownBlock: torch.Size([1, 512, 18, 30])\n",
      "UpBlock Input Shape: torch.Size([1, 512, 18, 30])\n",
      "After UpConv: torch.Size([1, 256, 36, 60])\n",
      "After DoubleConv UpBlock: torch.Size([1, 256, 36, 60])\n",
      "UpBlock Input Shape: torch.Size([1, 256, 36, 60])\n",
      "After UpConv: torch.Size([1, 128, 72, 120])\n",
      "Skip Connection Shape: torch.Size([1, 256, 72, 120])\n",
      "After Concatenation: torch.Size([1, 384, 72, 120])\n",
      "After DoubleConv UpBlock: torch.Size([1, 128, 72, 120])\n",
      "UpBlock Input Shape: torch.Size([1, 128, 72, 120])\n",
      "After UpConv: torch.Size([1, 5, 144, 240])\n",
      "After DoubleConv UpBlock: torch.Size([1, 5, 144, 240])\n",
      "Final Output Shape: torch.Size([1, 128, 144, 240])\n",
      "torch.Size([1, 128, 144, 240])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Utilities.Unet import Unet\n",
    "\n",
    "# Define input tensor\n",
    "input_tensor = torch.randn(1, 5, 144, 240)\n",
    "\n",
    "# Define block dimensions\n",
    "block_dimensions = [5, 128, 256, 512]\n",
    "\n",
    "# Set output channels\n",
    "output_channels = 128\n",
    "\n",
    "# Adjusted up block concatenation flags and skip connection indices\n",
    "up_block_use_concat = [False, True, False]  # Length matches the number of up blocks\n",
    "skip_connection_indices = [1]  # Adjusted to match the number of True values\n",
    "\n",
    "# Initialize the Unet model\n",
    "model = Unet(\n",
    "    block_dimensions=block_dimensions,\n",
    "    output_channels=output_channels,\n",
    "    up_block_use_concat=up_block_use_concat,\n",
    "    skip_connection_indices=skip_connection_indices\n",
    ")\n",
    "\n",
    "# Forward pass\n",
    "output = model(input_tensor)\n",
    "\n",
    "# Check the output shape\n",
    "print(output.shape)  # Should be [1, 128, 256, 256]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a86a18-17bb-409b-a176-c6a612456996",
   "metadata": {},
   "source": [
    "# Testing Spade Functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bace2543-95ce-4737-866f-eca8a306f9df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape with default noise behavior: torch.Size([8, 128, 64, 64])\n",
      "Output shape with noise enabled: torch.Size([8, 128, 64, 64])\n",
      "Output shape with noise disabled: torch.Size([8, 128, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the SPADEGeneratorUnit\n",
    "\n",
    "import torch\n",
    "from Utilities.Spade import SPADEGeneratorUnit  # Ensure this path is correct\n",
    "\n",
    "# Define parameters\n",
    "in_channels = 5               # Number of channels in input feature map x\n",
    "out_channels = 128             # Desired number of output features\n",
    "mask_channels = 3              # Number of channels in the mask\n",
    "kernel_size = 3                # Convolution kernel size\n",
    "pad_mode = 'constant'          # Padding mode for F.pad (zero-padding)\n",
    "upsampling = True              # Whether to apply upsampling\n",
    "\n",
    "# Initialize the SPADEGeneratorUnit\n",
    "spade_gen_unit = SPADEGeneratorUnit(\n",
    "    in_channels=in_channels,\n",
    "    out_channels=out_channels,\n",
    "    mask_channels=mask_channels,\n",
    "    kernel_size=kernel_size,\n",
    "    padding_mode=pad_mode\n",
    ")\n",
    "\n",
    "# Move model to device (optional, but recommended)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "spade_gen_unit.to(device)\n",
    "\n",
    "# Create dummy input tensors\n",
    "batch_size = 8\n",
    "height, width = 64, 64               # Spatial dimensions of input x\n",
    "mask_height, mask_width = 64, 64     # Spatial dimensions of mask\n",
    "\n",
    "# Input feature map x\n",
    "x = torch.randn(batch_size, in_channels, height, width).to(device)\n",
    "\n",
    "# Input mask\n",
    "mask = torch.randn(batch_size, mask_channels, mask_height, mask_width).to(device)\n",
    "\n",
    "# Forward pass through the SPADEGeneratorUnit with default noise behavior\n",
    "output_default = spade_gen_unit(x, mask)\n",
    "print(\"Output shape with default noise behavior:\", output_default.shape)\n",
    "# Expected Output Shape: [8, 128, 128, 128]\n",
    "\n",
    "# Forward pass through the SPADEGeneratorUnit with noise explicitly enabled\n",
    "output_with_noise = spade_gen_unit(x, mask, add_noise=True)\n",
    "print(\"Output shape with noise enabled:\", output_with_noise.shape)\n",
    "# Expected Output Shape: [8, 128, 128, 128]\n",
    "\n",
    "# Forward pass through the SPADEGeneratorUnit with noise explicitly disabled\n",
    "output_without_noise = spade_gen_unit(x, mask, add_noise=False)\n",
    "print(\"Output shape with noise disabled:\", output_without_noise.shape)\n",
    "# Expected Output Shape: [8, 128, 128, 128]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d08a15-d020-4d77-b71f-ff86277f6b04",
   "metadata": {},
   "source": [
    "# Testing Resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "649fe27e-3217-454a-9593-92bafdcfeca3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Initial Conv: torch.Size([8, 64, 128, 256])\n",
      "After ResNetBlock 1: torch.Size([8, 64, 128, 256])\n",
      "After Pooling 1: torch.Size([8, 64, 64, 128])\n",
      "After ResNetBlock 2: torch.Size([8, 128, 64, 128])\n",
      "After Pooling 2: torch.Size([8, 128, 32, 64])\n",
      "After ResNetBlock 3: torch.Size([8, 256, 32, 64])\n",
      "After Pooling 3: torch.Size([8, 256, 16, 32])\n",
      "After ResNetBlock 4: torch.Size([8, 512, 16, 32])\n",
      "Final Output shape: torch.Size([8, 512, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "# Example usage of the ResNet and ResNetUnit\n",
    "import torch\n",
    "from Utilities.ResNet import ResNet\n",
    "\n",
    "# Define parameters\n",
    "in_channels = 3          # Number of input channels\n",
    "block_dimensions = [64, 128, 256, 512]  # Feature dimensions for each residual block\n",
    "kernel_size = 3          # Convolution kernel size\n",
    "pooling = True           # Whether to apply max pooling after residual blocks\n",
    "padding_mode = 'reflect' # Padding mode for convolutional layers\n",
    "# Initialize the ResNet model\n",
    "resnet = ResNet(\n",
    "    in_channels=in_channels, \n",
    "    block_dimensions=block_dimensions, \n",
    "    kernel_size=kernel_size,\n",
    "    pooling=pooling, \n",
    "    padding_mode=padding_mode\n",
    ")\n",
    "# Create a dummy input tensor\n",
    "batch_size = 8\n",
    "height, width = 128, 256   # Spatial dimensions of the input\n",
    "x = torch.randn(batch_size, in_channels, height, width)\n",
    "# Forward pass through the ResNet\n",
    "output = resnet(x)\n",
    "# Check the output shape\n",
    "print(\"Final Output shape:\", output.shape)  # Expected shape depends on pooling and block_dimensions\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f117876-9624-41d4-b29b-bcd6ee96a4af",
   "metadata": {},
   "source": [
    "# Testing Advection, Diffusion, Poisson & Finite Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e03c842-3a6f-49a5-944e-616396c2be07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advection Output Shape: torch.Size([4, 1, 64, 64])\n",
      "Laplacian Output Shape: torch.Size([4, 3, 64, 64])\n",
      "Poisson Outputs Shapes:\n",
      "ux2: torch.Size([4, 3, 64, 64])\n",
      "vy2: torch.Size([4, 3, 64, 64])\n",
      "uyvx: torch.Size([4, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# example_usage.py\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from Differentiator.Advection import Advection\n",
    "from Differentiator.Diffusion import Diffusion\n",
    "from Integrator.Poisson import Poisson  # Import Poisson from Integrator\n",
    "\n",
    "def main():\n",
    "    # Define parameters\n",
    "    channel_size = 3  # Example: RGB channels\n",
    "    cd_filter_1d = np.array([-1.0, 1.0])\n",
    "    padding = \"SYMMETRIC\"\n",
    "\n",
    "    # Instantiate the Advection, Diffusion, and Poisson layers\n",
    "    advection_layer = Advection(channel_size=channel_size, \n",
    "                                cd_filter_1d=cd_filter_1d, \n",
    "                                padding_mode=padding)\n",
    "    \n",
    "    diffusion_layer = Diffusion(channel_size=channel_size, \n",
    "                                 cd_filter_1d=cd_filter_1d, \n",
    "                                 padding_mode=padding)\n",
    "    \n",
    "    poisson_layer = Poisson(channel_size=channel_size, \n",
    "                             cd_filter_1d=cd_filter_1d, \n",
    "                             padding_mode=padding)\n",
    "\n",
    "    # Move layers to GPU if available\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    advection_layer.to(device)\n",
    "    diffusion_layer.to(device)\n",
    "    poisson_layer.to(device)\n",
    "\n",
    "    # Create dummy inputs\n",
    "    batch_size = 4\n",
    "    C = channel_size\n",
    "    H, W = 64, 64  # Spatial dimensions\n",
    "\n",
    "    state_variable = torch.randn(batch_size, C, H, W).to(device)      # [N, C, H, W]\n",
    "    velocity_field = torch.randn(batch_size, 2*C, H, W).to(device)  # [N, 2C, H-1, W-1]\n",
    "    vector_field = [torch.randn(batch_size, C, H, W).to(device),   # First component\n",
    "                    torch.randn(batch_size, C, H, W).to(device)]   # Second component\n",
    "\n",
    "    # Forward pass through Advection layer\n",
    "    advect = advection_layer(state_variable, velocity_field)\n",
    "    print(\"Advection Output Shape:\", advect.shape)  # Expected: [4, 1, 63, 63]\n",
    "\n",
    "    # Forward pass through Diffusion layer\n",
    "    laplacian = diffusion_layer(state_variable)\n",
    "    print(\"Laplacian Output Shape:\", laplacian.shape)  # Expected: [4, 3, 62, 62]\n",
    "\n",
    "    # Forward pass through Poisson layer\n",
    "    ux2, vy2, uyvx = poisson_layer(vector_field)\n",
    "    print(\"Poisson Outputs Shapes:\")\n",
    "    print(\"ux2:\", ux2.shape)   # Expected: [4, 3, 63, 63]\n",
    "    print(\"vy2:\", vy2.shape)   # Expected: [4, 3, 63, 63]\n",
    "    print(\"uyvx:\", uyvx.shape) # Expected: [4, 3, 63, 63]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ee3133-9013-43bb-a3b8-1a10b70d9b70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Initial Conv: torch.Size([4, 128, 128, 192])\n",
      "After ResNetBlock 1: torch.Size([4, 128, 128, 192])\n",
      "After ResNetBlock 2: torch.Size([4, 128, 128, 192])\n",
      "Output Shape: torch.Size([4, 2, 128, 192])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from Differentiator.MappingAndRecon import MappingAndRecon\n",
    "\n",
    "def main():\n",
    "    # Define parameters\n",
    "    n_base_features = 128\n",
    "    n_mask_channel = 2\n",
    "    output_channel = 2\n",
    "    padding_mode = \"constant\"  # Ensure lowercase\n",
    "\n",
    "    # Instantiate the model\n",
    "    model = MappingAndRecon(\n",
    "        n_base_features=n_base_features,\n",
    "        n_mask_channel=n_mask_channel,\n",
    "        output_channel=output_channel,\n",
    "        padding_mode=padding_mode\n",
    "    )\n",
    "\n",
    "    # Move model to device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    # Create dummy inputs with arbitrary spatial dimensions\n",
    "    batch_size = 4\n",
    "    C = n_base_features\n",
    "    M = n_mask_channel\n",
    "    H, W = 128, 192  # Example spatial dimensions; can be changed as needed\n",
    "\n",
    "    dynamic_feature = torch.randn(batch_size, C, H, W).to(device)      # [N, C, H, W]\n",
    "    advec_diff = torch.randn(batch_size, M, H, W).to(device)          # [N, M, H, W]\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(dynamic_feature, advec_diff)\n",
    "    print(\"Output Shape:\", output.shape)  # Expected: [4, 2, H_out, W_out]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25c37c07-8dbf-4a2f-8c99-360a5b61929f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DownBlock Input Shape: torch.Size([8, 6, 128, 256])\n",
      "After DoubleConv DownBlock: torch.Size([8, 64, 128, 256])\n",
      "After Pooling DownBlock: torch.Size([8, 64, 64, 128])\n",
      "After Initial Conv: torch.Size([8, 64, 128, 256])\n",
      "After ResNetBlock 1: torch.Size([8, 64, 128, 256])\n",
      "After ResNetBlock 2: torch.Size([8, 64, 128, 256])\n",
      "Final Output shape: torch.Size([8, 1, 128, 256])\n"
     ]
    }
   ],
   "source": [
    "# test_PoissonBlock.py\n",
    "\n",
    "import torch\n",
    "from Integrator.Poisson import PoissonBlock  # Ensure the import path is correct\n",
    "\n",
    "# Define parameters\n",
    "n_base_features = 64  # Number of base feature channels\n",
    "\n",
    "# Initialize the PoissonBlock\n",
    "poisson_block = PoissonBlock(n_base_features=n_base_features)\n",
    "\n",
    "# Create a dummy input tensor\n",
    "batch_size = 8\n",
    "channels = 3  # Assuming 3 channels as per the original TensorFlow code\n",
    "height, width = 128, 256  # Example spatial dimensions\n",
    "x = torch.randn(batch_size, channels, height, width)\n",
    "\n",
    "# Forward pass through the PoissonBlock\n",
    "output = poisson_block(x)\n",
    "\n",
    "# Check the output shape\n",
    "print(\"Final Output shape:\", output.shape)  # Expected: [8, 1, 128, 256]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6816a-54fe-4848-b50d-faf261c5f4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
